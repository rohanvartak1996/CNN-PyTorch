{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_s6vogWApul"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5TQ6ipJApux"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bUAlJ0OJApu0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_AZt7TGxCIt"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5vhNZ0ttApu9",
    "outputId": "6b3b40cc-e6bd-4db0-bade-69dfd6a091f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomCrop(32, padding=4),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddAAy5fPF7qu"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjHC05KlApvD"
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmD3Y_RdypVo"
   },
   "outputs": [],
   "source": [
    "class CNN4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4,self).__init__()\n",
    "        #network architecture\n",
    "        self.conv11 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.batchn1 = nn.BatchNorm2d(32)\n",
    "        self.conv21 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv22 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.batchn2 = nn.BatchNorm2d(64)\n",
    "        self.conv31 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv32 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.batchn3 = nn.BatchNorm2d(128)\n",
    "        self.conv41 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv42 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.batchn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.linear1 = nn.Linear(256*2*2, 256)\n",
    "        self.linear2 = nn.Linear(256, 128)\n",
    "        self.linear3 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #forward pass\n",
    "        #x is the input\n",
    "        x = (F.relu(self.conv11(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv12(x))))\n",
    "        x = (F.relu(self.conv21(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv22(x))))\n",
    "        x = (F.relu(self.conv31(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv32(x))))\n",
    "        x = (F.relu(self.conv41(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv42(x))))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 256*2*2) ## reshaping \n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.softmax(self.linear3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "l2-uns15W__N",
    "outputId": "726d1d6d-7641-451c-fcb5-f2dab54a1797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN4(\n",
      "  (conv11): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv21): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv31): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv32): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv41): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv42): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop): Dropout(p=0.25)\n",
      "  (linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (linear3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN4()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "IdHarQF7tz1M",
    "outputId": "9e4454e2-9763-4b7b-98bb-0874b44c31d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN4(\n",
       "  (conv11): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv21): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv31): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv32): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv41): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv42): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop): Dropout(p=0.25)\n",
       "  (linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (linear3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "cnn.cuda()\n",
    "cnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuJFfj7Nt2Ht"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwyKtee9t5kd"
   },
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "train_loss, train_accu = [], []\n",
    "\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3KqlVLewmVX"
   },
   "outputs": [],
   "source": [
    "#scheduler = MultiStepLR(optimizer, milestones=[75, 100], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "BmqFeBHlLjyy",
    "outputId": "ee532802-bcfe-42a6-e1e6-63abb973e9e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Step: 0\tLoss: 2.300\tAccuracy: 10.938\n",
      "Epoch: 1\tTrain Step: 0\tLoss: 1.673\tAccuracy: 36.719\n",
      "Epoch: 2\tTrain Step: 0\tLoss: 1.488\tAccuracy: 46.094\n",
      "Epoch: 3\tTrain Step: 0\tLoss: 1.151\tAccuracy: 60.938\n",
      "Epoch: 4\tTrain Step: 0\tLoss: 1.014\tAccuracy: 57.812\n",
      "Epoch: 5\tTrain Step: 0\tLoss: 0.840\tAccuracy: 70.312\n",
      "Epoch: 6\tTrain Step: 0\tLoss: 0.851\tAccuracy: 62.500\n",
      "Epoch: 7\tTrain Step: 0\tLoss: 0.818\tAccuracy: 71.875\n",
      "Epoch: 8\tTrain Step: 0\tLoss: 0.897\tAccuracy: 66.406\n",
      "Epoch: 9\tTrain Step: 0\tLoss: 1.030\tAccuracy: 63.281\n",
      "Epoch: 10\tTrain Step: 0\tLoss: 0.915\tAccuracy: 64.062\n",
      "Epoch: 11\tTrain Step: 0\tLoss: 0.568\tAccuracy: 80.469\n",
      "Epoch: 12\tTrain Step: 0\tLoss: 0.820\tAccuracy: 74.219\n",
      "Epoch: 13\tTrain Step: 0\tLoss: 0.693\tAccuracy: 75.000\n",
      "Epoch: 14\tTrain Step: 0\tLoss: 0.815\tAccuracy: 69.531\n",
      "Epoch: 15\tTrain Step: 0\tLoss: 0.814\tAccuracy: 74.219\n",
      "Epoch: 16\tTrain Step: 0\tLoss: 0.640\tAccuracy: 78.125\n",
      "Epoch: 17\tTrain Step: 0\tLoss: 0.689\tAccuracy: 77.344\n",
      "Epoch: 18\tTrain Step: 0\tLoss: 0.692\tAccuracy: 75.781\n",
      "Epoch: 19\tTrain Step: 0\tLoss: 0.765\tAccuracy: 74.219\n",
      "Epoch: 20\tTrain Step: 0\tLoss: 0.429\tAccuracy: 88.281\n",
      "Epoch: 21\tTrain Step: 0\tLoss: 0.540\tAccuracy: 78.906\n",
      "Epoch: 22\tTrain Step: 0\tLoss: 0.570\tAccuracy: 82.031\n",
      "Epoch: 23\tTrain Step: 0\tLoss: 0.553\tAccuracy: 83.594\n",
      "Epoch: 24\tTrain Step: 0\tLoss: 0.614\tAccuracy: 77.344\n",
      "Epoch: 25\tTrain Step: 0\tLoss: 0.534\tAccuracy: 83.594\n",
      "Epoch: 26\tTrain Step: 0\tLoss: 0.626\tAccuracy: 82.812\n",
      "Epoch: 27\tTrain Step: 0\tLoss: 0.689\tAccuracy: 76.562\n",
      "Epoch: 28\tTrain Step: 0\tLoss: 0.598\tAccuracy: 77.344\n",
      "Epoch: 29\tTrain Step: 0\tLoss: 0.569\tAccuracy: 81.250\n",
      "Epoch: 30\tTrain Step: 0\tLoss: 0.359\tAccuracy: 87.500\n",
      "Epoch: 31\tTrain Step: 0\tLoss: 0.512\tAccuracy: 79.688\n",
      "Epoch: 32\tTrain Step: 0\tLoss: 0.439\tAccuracy: 85.156\n",
      "Epoch: 33\tTrain Step: 0\tLoss: 0.578\tAccuracy: 80.469\n",
      "Epoch: 34\tTrain Step: 0\tLoss: 0.447\tAccuracy: 85.938\n",
      "Epoch: 35\tTrain Step: 0\tLoss: 0.418\tAccuracy: 85.156\n",
      "Epoch: 36\tTrain Step: 0\tLoss: 0.513\tAccuracy: 75.781\n",
      "Epoch: 37\tTrain Step: 0\tLoss: 0.502\tAccuracy: 77.344\n",
      "Epoch: 38\tTrain Step: 0\tLoss: 0.499\tAccuracy: 78.125\n",
      "Epoch: 39\tTrain Step: 0\tLoss: 0.521\tAccuracy: 80.469\n",
      "Epoch: 40\tTrain Step: 0\tLoss: 0.561\tAccuracy: 80.469\n",
      "Epoch: 41\tTrain Step: 0\tLoss: 0.598\tAccuracy: 78.125\n",
      "Epoch: 42\tTrain Step: 0\tLoss: 0.487\tAccuracy: 84.375\n",
      "Epoch: 43\tTrain Step: 0\tLoss: 0.404\tAccuracy: 87.500\n",
      "Epoch: 44\tTrain Step: 0\tLoss: 0.435\tAccuracy: 85.938\n",
      "Epoch: 45\tTrain Step: 0\tLoss: 0.737\tAccuracy: 76.562\n",
      "Epoch: 46\tTrain Step: 0\tLoss: 0.522\tAccuracy: 78.906\n",
      "Epoch: 47\tTrain Step: 0\tLoss: 0.414\tAccuracy: 84.375\n",
      "Epoch: 48\tTrain Step: 0\tLoss: 0.358\tAccuracy: 85.156\n",
      "Epoch: 49\tTrain Step: 0\tLoss: 0.422\tAccuracy: 89.062\n",
      "Epoch: 50\tTrain Step: 0\tLoss: 0.347\tAccuracy: 89.062\n",
      "Epoch: 51\tTrain Step: 0\tLoss: 0.576\tAccuracy: 81.250\n",
      "Epoch: 52\tTrain Step: 0\tLoss: 0.654\tAccuracy: 75.000\n",
      "Epoch: 53\tTrain Step: 0\tLoss: 0.402\tAccuracy: 88.281\n",
      "Epoch: 54\tTrain Step: 0\tLoss: 0.482\tAccuracy: 80.469\n",
      "Epoch: 55\tTrain Step: 0\tLoss: 0.515\tAccuracy: 82.812\n",
      "Epoch: 56\tTrain Step: 0\tLoss: 0.369\tAccuracy: 86.719\n",
      "Epoch: 57\tTrain Step: 0\tLoss: 0.615\tAccuracy: 85.156\n",
      "Epoch: 58\tTrain Step: 0\tLoss: 0.489\tAccuracy: 81.250\n",
      "Epoch: 59\tTrain Step: 0\tLoss: 0.411\tAccuracy: 85.938\n",
      "Epoch: 60\tTrain Step: 0\tLoss: 0.392\tAccuracy: 86.719\n",
      "Epoch: 61\tTrain Step: 0\tLoss: 0.353\tAccuracy: 86.719\n",
      "Epoch: 62\tTrain Step: 0\tLoss: 0.433\tAccuracy: 87.500\n",
      "Epoch: 63\tTrain Step: 0\tLoss: 0.394\tAccuracy: 86.719\n",
      "Epoch: 64\tTrain Step: 0\tLoss: 0.347\tAccuracy: 88.281\n",
      "Epoch: 65\tTrain Step: 0\tLoss: 0.457\tAccuracy: 83.594\n",
      "Epoch: 66\tTrain Step: 0\tLoss: 0.313\tAccuracy: 92.969\n",
      "Epoch: 67\tTrain Step: 0\tLoss: 0.385\tAccuracy: 85.938\n",
      "Epoch: 68\tTrain Step: 0\tLoss: 0.480\tAccuracy: 81.250\n",
      "Epoch: 69\tTrain Step: 0\tLoss: 0.420\tAccuracy: 86.719\n",
      "Epoch: 70\tTrain Step: 0\tLoss: 0.436\tAccuracy: 85.156\n",
      "Epoch: 71\tTrain Step: 0\tLoss: 0.404\tAccuracy: 81.250\n",
      "Epoch: 72\tTrain Step: 0\tLoss: 0.418\tAccuracy: 82.812\n",
      "Epoch: 73\tTrain Step: 0\tLoss: 0.438\tAccuracy: 85.156\n",
      "Epoch: 74\tTrain Step: 0\tLoss: 0.384\tAccuracy: 85.938\n",
      "Epoch: 75\tTrain Step: 0\tLoss: 0.457\tAccuracy: 85.938\n",
      "Epoch: 76\tTrain Step: 0\tLoss: 0.555\tAccuracy: 81.250\n",
      "Epoch: 77\tTrain Step: 0\tLoss: 0.414\tAccuracy: 88.281\n",
      "Epoch: 78\tTrain Step: 0\tLoss: 0.438\tAccuracy: 85.938\n",
      "Epoch: 79\tTrain Step: 0\tLoss: 0.539\tAccuracy: 80.469\n",
      "Epoch: 80\tTrain Step: 0\tLoss: 0.605\tAccuracy: 79.688\n",
      "Epoch: 81\tTrain Step: 0\tLoss: 0.416\tAccuracy: 84.375\n",
      "Epoch: 82\tTrain Step: 0\tLoss: 0.418\tAccuracy: 84.375\n",
      "Epoch: 83\tTrain Step: 0\tLoss: 0.366\tAccuracy: 88.281\n",
      "Epoch: 84\tTrain Step: 0\tLoss: 0.352\tAccuracy: 89.062\n",
      "Epoch: 85\tTrain Step: 0\tLoss: 0.499\tAccuracy: 84.375\n",
      "Epoch: 86\tTrain Step: 0\tLoss: 0.406\tAccuracy: 85.938\n",
      "Epoch: 87\tTrain Step: 0\tLoss: 0.370\tAccuracy: 88.281\n",
      "Epoch: 88\tTrain Step: 0\tLoss: 0.541\tAccuracy: 82.031\n",
      "Epoch: 89\tTrain Step: 0\tLoss: 0.532\tAccuracy: 79.688\n",
      "Epoch: 90\tTrain Step: 0\tLoss: 0.370\tAccuracy: 86.719\n",
      "Epoch: 91\tTrain Step: 0\tLoss: 0.343\tAccuracy: 91.406\n",
      "Epoch: 92\tTrain Step: 0\tLoss: 0.326\tAccuracy: 87.500\n",
      "Epoch: 93\tTrain Step: 0\tLoss: 0.434\tAccuracy: 85.156\n",
      "Epoch: 94\tTrain Step: 0\tLoss: 0.414\tAccuracy: 84.375\n",
      "Epoch: 95\tTrain Step: 0\tLoss: 0.423\tAccuracy: 86.719\n",
      "Epoch: 96\tTrain Step: 0\tLoss: 0.347\tAccuracy: 86.719\n",
      "Epoch: 97\tTrain Step: 0\tLoss: 0.430\tAccuracy: 84.375\n",
      "Epoch: 98\tTrain Step: 0\tLoss: 0.401\tAccuracy: 83.594\n",
      "Epoch: 99\tTrain Step: 0\tLoss: 0.340\tAccuracy: 91.406\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i,data in enumerate(trainloader, 0):\n",
    "            #get the inputs\n",
    "            X,y  = data\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = cnn(X)\n",
    "            loss = loss_function(outputs, y)\n",
    "            loss.backward()\n",
    "            train_loss.append(loss.item())\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            predictions = outputs.data.max(1)[1]\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            accuracy = np.sum(predictions.cpu().numpy()==y.cpu().numpy())/batch_size*100\n",
    "            train_accu.append(accuracy)\n",
    "            if i % 10000 == 0:\n",
    "              print('Epoch: {}\\tTrain Step: {}\\tLoss: {:.3f}\\tAccuracy: {:.3f}'.format(epoch, i, loss.item(), accuracy))\n",
    "            #i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bQp_zYTEXIT"
   },
   "outputs": [],
   "source": [
    "def save_predictions(file, y):\n",
    "    np.save(file, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AvktZT3xSzPK",
    "outputId": "5b3bddc9-65f6-4c6b-fe6c-9778a763393b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 87.00%\n"
     ]
    }
   ],
   "source": [
    "cnn.eval()\n",
    "correct = 0\n",
    "final = []\n",
    "for images, labels in testloader:\n",
    "    with torch.no_grad(): \n",
    "        images, labels = images.cuda(), labels.cuda() \n",
    "        outputs = cnn(images)\n",
    "        predictions = outputs.data.max(1)[1]\n",
    "        pred = predictions.cpu().numpy()\n",
    "        #print(pred.shape)\n",
    "        final.extend(pred.tolist())\n",
    "        #print(pred)\n",
    "        correct += predictions.eq(labels.data).sum()\n",
    "        \n",
    "print('Test set accuracy: {:.2f}%'.format(100.0 * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRWSD5svv6tq"
   },
   "source": [
    "# Model Architechture Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KITPygBMwH1z"
   },
   "source": [
    "**First**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mdi1W_u1wPfk"
   },
   "source": [
    "Using a simple architecture for 1st testing of the model\n",
    "3 convolutional layers with max-pooling and 2 fully connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aqGgI_u2w8fW"
   },
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2,self).__init__()\n",
    "        #network architecture\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.linear1 = nn.Linear(64*4*4, 512)\n",
    "        self.linear2 = nn.Linear(512, 10)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        #forward pass\n",
    "        #x is the input\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 64*4*4) ## reshaping \n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ip8tpLawxI52"
   },
   "source": [
    "Got an accuracy of 54%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0iVG8_hxxPLW"
   },
   "source": [
    "**Second**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XnYe1wsmxSLF"
   },
   "source": [
    "Adding more convolutional layers and introducing a drop out of 0.25 for each layer\n",
    "\n",
    "Using stochastic gradient descent with momentum and weight decay "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gxdUNBHax0RS"
   },
   "source": [
    "class CNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3,self).__init__()\n",
    "        #network architecture\n",
    "        self.conv11 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv21 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv22 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv31 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv32 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.linear1 = nn.Linear(128*4*4, 512)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.linear3 = nn.Linear(256, 10)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        #forward pass\n",
    "        #x is the input\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = self.drop(self.pool(F.relu(self.conv12(x))))\n",
    "        x = F.relu(self.conv21(x))\n",
    "        x = self.drop(self.pool(F.relu(self.conv22(x))))\n",
    "        x = F.relu(self.conv31(x))\n",
    "        x = self.drop(self.pool(F.relu(self.conv32(x))))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 128*4*4) ## reshaping \n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNolRRaSx6R6"
   },
   "source": [
    "Got an accuracy of 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eNI7kHAXyCwf"
   },
   "source": [
    "**Third**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCQMTxi-yGCH"
   },
   "source": [
    "Still increasing the convolutional layers and now using a deeper network for the fully connected part\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKuGIcIyyps4"
   },
   "source": [
    "**Fourth**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TlxL1MJ6ytQq"
   },
   "source": [
    "Tried various experimentations with the batch size and learning rate ,\n",
    "\n",
    "The accuracy ranged between 75% and 80%\n",
    "\n",
    "Then tried to introduce batch normalization \n",
    "\n",
    "Did not achieve resulta as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTkSllpIzE29"
   },
   "source": [
    "**Fifth**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vRuRbIMvz_y0"
   },
   "source": [
    "Change in the architecture instead of using straight convolutional layer\n",
    "\n",
    "Used a combination of convolutional and actiivation layer followed by a convolution activation and a dropout\n",
    "\n",
    "This architecture will help in properly convolving the images and drop out will help to a better generalization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alm4zpirzHcD"
   },
   "source": [
    "Tried to introduce a learning rate schedule for stochastic gradient descent\n",
    "\n",
    "Still requiring a lot of epochs to achieve above 80% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "He5Aho2Tz3bh"
   },
   "source": [
    "class CNN4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4,self).__init__()\n",
    "        #network architecture\n",
    "        self.conv11 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.batchn1 = nn.BatchNorm2d(32)\n",
    "        self.conv21 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv22 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.batchn2 = nn.BatchNorm2d(64)\n",
    "        self.conv31 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv32 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.batchn3 = nn.BatchNorm2d(128)\n",
    "        self.conv41 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv42 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.batchn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.linear1 = nn.Linear(256*2*2, 256)\n",
    "        self.linear2 = nn.Linear(256, 128)\n",
    "        self.linear3 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #forward pass\n",
    "        #x is the input\n",
    "        x = (F.relu(self.conv11(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv12(x))))\n",
    "        x = (F.relu(self.conv21(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv22(x))))\n",
    "        x = (F.relu(self.conv31(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv32(x))))\n",
    "        x = (F.relu(self.conv41(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv42(x))))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 256*2*2) ## reshaping \n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.softmax(self.linear3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eScu1xldzVV-"
   },
   "source": [
    "**Sixth**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BbBC7Y2NzXCN"
   },
   "source": [
    "Finally decided to use Adam optimizer with a weight decay\n",
    "\n",
    "The batch size is decided to be 128\n",
    "\n",
    "Decided to train for 80 epochs\n",
    "\n",
    "Got an accuracy of 87%\n",
    "\n",
    "Did not use batch normalization only used dropout of 0.25 for each convolutional layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Jnp4Kwt0g-K"
   },
   "source": [
    "**Final Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GoBbpEyM0kcO"
   },
   "source": [
    "class CNN4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4,self).__init__()\n",
    "        #network architecture\n",
    "        self.conv11 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.batchn1 = nn.BatchNorm2d(32)\n",
    "        self.conv21 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv22 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.batchn2 = nn.BatchNorm2d(64)\n",
    "        self.conv31 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv32 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.batchn3 = nn.BatchNorm2d(128)\n",
    "        self.conv41 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv42 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.batchn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.linear1 = nn.Linear(256*2*2, 256)\n",
    "        self.linear2 = nn.Linear(256, 128)\n",
    "        self.linear3 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #forward pass\n",
    "        #x is the input\n",
    "        x = (F.relu(self.conv11(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv12(x))))\n",
    "        x = (F.relu(self.conv21(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv22(x))))\n",
    "        x = (F.relu(self.conv31(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv32(x))))\n",
    "        x = (F.relu(self.conv41(x)))\n",
    "        x = self.drop(self.pool(F.relu(self.conv42(x))))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 256*2*2) ## reshaping \n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.softmax(self.linear3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RPhipy7Vyjhk"
   },
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulz0g02Gx5KU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW1-CNN-rpv224-opk207.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
